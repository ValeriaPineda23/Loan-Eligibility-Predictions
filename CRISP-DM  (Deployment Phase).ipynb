{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66967c8d",
   "metadata": {},
   "source": [
    "# Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "552d2110",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard libraries for data analysis:\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.stats import norm, skew\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# sklearn modules for data preprocessing:\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#sklearn modules for Model Selection:\n",
    "from sklearn import svm, tree, linear_model, neighbors\n",
    "from sklearn import naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#sklearn modules for Model Evaluation & Improvement:    \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score \n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, fbeta_score\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, precision_recall_curve\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import make_scorer, recall_score, log_loss\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "#Standard libraries for data visualization:\n",
    "import seaborn as sn\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib \n",
    "%matplotlib inline\n",
    "color = sn.color_palette()\n",
    "import matplotlib.ticker as mtick\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "#Miscellaneous Utilitiy Libraries:    \n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import timeit\n",
    "import string\n",
    "import time\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "from dateutil.parser import parse\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5119e2",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60e2d63",
   "metadata": {},
   "source": [
    "Finally, we applied the best model obtained to make predictions using the attached predict.csv as the test set and the information from loan.csv as training set. We created a new Jupyter Notebook that cleans the predict.csv dataset by imputing missing values, labeling and applying one-hot encoding on categorical data, transforming continuous values into integers, and selecting the essential features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7a9557",
   "metadata": {},
   "source": [
    "#### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64761166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Data\n",
    "data = pd.read_csv('predict.csv')\n",
    "del data['Loan_ID']\n",
    "data['Credit_History'] = data['Credit_History'].astype(object)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee60d54",
   "metadata": {},
   "source": [
    "#### Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62cc123c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat = data.select_dtypes(include=['object'])\n",
    "data_num = data.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfd9dea2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>2.997275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Married</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dependents</th>\n",
       "      <td>2.724796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Self_Employed</th>\n",
       "      <td>6.267030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_History</th>\n",
       "      <td>7.901907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Property_Area</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      NA\n",
       "Gender          2.997275\n",
       "Married         0.000000\n",
       "Dependents      2.724796\n",
       "Education       0.000000\n",
       "Self_Employed   6.267030\n",
       "Credit_History  7.901907\n",
       "Property_Area   0.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data_cat.isnull().sum()/len(data_cat)*100,columns=[\"NA\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cb7509",
   "metadata": {},
   "source": [
    "*From here we have 4 categorical variables with missing data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8119f89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoanAmount</th>\n",
       "      <td>1.362398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <td>1.634877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         NA\n",
       "ApplicantIncome    0.000000\n",
       "CoapplicantIncome  0.000000\n",
       "LoanAmount         1.362398\n",
       "Loan_Amount_Term   1.634877"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data_num.isnull().sum()/len(data_num)*100,columns=[\"NA\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca9cab0",
   "metadata": {},
   "source": [
    "*From here we have 2 numerical variables with missing data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b81c905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imp.fit(data_cat)\n",
    "data_cat_new = pd.DataFrame(imp.transform(data_cat))\n",
    "data_cat_new.columns = data_cat.columns\n",
    "df_cat = data_cat_new.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aeb7c76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "nan = np.nan\n",
    "imp = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "data_num_new_1 = pd.DataFrame(imp.fit_transform(data_num))\n",
    "data_num_new_1.columns = data_num.columns\n",
    "\n",
    "sc_X = MinMaxScaler()\n",
    "data_num_new = pd.DataFrame(sc_X.fit_transform(data_num_new_1))\n",
    "data_num_new.columns = data_num_new_1.columns\n",
    "\n",
    "df_num = data_num_new.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2d5e4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Married</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dependents</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Self_Employed</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_History</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Property_Area</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 NA\n",
       "Gender          0.0\n",
       "Married         0.0\n",
       "Dependents      0.0\n",
       "Education       0.0\n",
       "Self_Employed   0.0\n",
       "Credit_History  0.0\n",
       "Property_Area   0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data_cat_new.isnull().sum()/len(data_cat_new)*100,columns=[\"NA\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62767d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoanAmount</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    NA\n",
       "ApplicantIncome    0.0\n",
       "CoapplicantIncome  0.0\n",
       "LoanAmount         0.0\n",
       "Loan_Amount_Term   0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data_num_new.isnull().sum()/len(data_num_new)*100,columns=[\"NA\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf7ab15",
   "metadata": {},
   "source": [
    "#### Label encoding and One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e2f7e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender            2\n",
       "Married           2\n",
       "Dependents        4\n",
       "Education         2\n",
       "Self_Employed     2\n",
       "Credit_History    2\n",
       "Property_Area     3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cat_new.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43f037ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "n = 0\n",
    "for col in data_cat_new.columns[0:]:\n",
    "    le.fit(data_cat_new.loc[:,col])\n",
    "    data_cat_new.loc[:,col] = le.transform(data_cat_new.loc[:,col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72e260ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating instance of one-hot-encoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc_dep = pd.DataFrame(enc.fit_transform(data_cat_new[['Dependents']]).toarray())\n",
    "enc_dep =enc_dep.rename(columns={0: 'Dependendents_0',\n",
    "                              1: 'Dependendents_1',\n",
    "                              2: 'Dependendents_2',\n",
    "                              3: 'Dependendents_3'})\n",
    "\n",
    "enc_prop = pd.DataFrame(enc.fit_transform(data_cat_new[['Property_Area']]).toarray())\n",
    "enc_prop =enc_prop.rename(columns={0: 'Property_Area_0',\n",
    "                                   1: 'Property_Area_1',\n",
    "                                   2: 'Property_Area_2'})\n",
    "\n",
    "# merge with main df data_cat_new on key values\n",
    "data_cat_new = data_cat_new.join([enc_dep,enc_prop])\n",
    "sc_X = StandardScaler()\n",
    "\n",
    "data_cat_new = data_cat_new.drop(columns=['Dependents','Property_Area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cbd2bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data= data_cat_new.join([data_num_new])\n",
    "modeling_dataset = final_data[['Married', \n",
    "                               'Credit_History', \n",
    "                               'Property_Area_1', \n",
    "                               'ApplicantIncome', \n",
    "                               'CoapplicantIncome', \n",
    "                               'LoanAmount']]\n",
    "\n",
    "X_test = modeling_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507d706c",
   "metadata": {},
   "source": [
    "#### Train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b025fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel('Training Data.xlsx')\n",
    "train = train.iloc[: , 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f27338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[\"Loan_Status\"]\n",
    "y_train = np.where(y_train > 0.5, 1, 0)\n",
    "X_train = train.drop(columns=\"Loan_Status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96335f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number transactions X_train dataset:  (844, 6)\n",
      "Number transactions y_train dataset:  (844,)\n",
      "Number transactions X_test dataset:  (367, 6)\n"
     ]
    }
   ],
   "source": [
    "#to resolve any class imbalance - use stratify parameter.\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c118bc",
   "metadata": {},
   "source": [
    "# Applying Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535bc8fa",
   "metadata": {},
   "source": [
    "The predictions for each user are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e92d87a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################### Results Using Random Forest #####################\n",
      "[1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0\n",
      " 1 0 1 1 1 1 0 1 0 1 0 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 0 0 0 1 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 0\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 0\n",
      " 1 1 0 0 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate accuracy\n",
    "\n",
    "def train_using_RF(X_train, X_test, y_train):\n",
    "    # Creating the classifier object\n",
    "    clf = RandomForestClassifier(max_depth = 13, min_samples_leaf = 1, n_estimators=45, random_state = 0)\n",
    "    # Performing training\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf\n",
    "\n",
    "def prediction(X_test, clf_object):\n",
    "  \n",
    "    # Predicton on test with giniIndex\n",
    "    y_pred = clf_object.predict(X_test)\n",
    "    print(y_pred)\n",
    "    return y_pred\n",
    "\n",
    "clf = train_using_RF(X_train, X_test, y_train)\n",
    "\n",
    "print(\"##################### Results Using Random Forest #####################\")\n",
    "y_pred = prediction(X_test, clf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a84684",
   "metadata": {},
   "source": [
    "#### Download results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4bf1aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = pd.DataFrame(columns=['ID','Loan_Status'])\n",
    "data = pd.read_csv('predict.csv')\n",
    "model_results['ID']=data['Loan_ID']\n",
    "model_results['Loan_Status']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bcdb6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001031</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001035</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001051</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>LP002971</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>LP002975</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>LP002980</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>LP002986</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>LP002989</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>367 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  Loan_Status\n",
       "0    LP001015            1\n",
       "1    LP001022            1\n",
       "2    LP001031            1\n",
       "3    LP001035            1\n",
       "4    LP001051            0\n",
       "..        ...          ...\n",
       "362  LP002971            1\n",
       "363  LP002975            1\n",
       "364  LP002980            1\n",
       "365  LP002986            1\n",
       "366  LP002989            0\n",
       "\n",
       "[367 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results.to_excel('Model Predictions.xlsx')\n",
    "model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fecb29",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82201532",
   "metadata": {},
   "source": [
    "In conclusion, we used the Dream Housing Finance Loan dataset to build a machine learning classifier to automate the loan eligibility process. This model attained a ROC/AUC score of accuracy. Additionally, according to this analysis, we can conclude that the customer segments that DHF should target are applicants that appear to be married and are looking for a property in the suburban area. This situation could mean that they may be planning to grow a family; thus, they have a higher probability of being responsible for avoiding debts. Furthermore, these applicants and their co-applicants, should count on a high amount of income. If DHF targets people who follow these characteristics, they can ensure that customers will be capable of paying back; thus, DHF will be more secure in lending a higher amount of money to them. Finally, and most importantly, ensure that the person has a credit history because applicants who have repaid their previous debts have a significantly higher probability of repaying this one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
